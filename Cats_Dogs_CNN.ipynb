{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e655bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #provides a way of interacting with the operating system. It's commonly used for tasks like file and directory manipulation.\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "#ImageDataGenerator is used for data augmentation and preprocessing of images, which is essential for training deep learning models on image data.\n",
    "from tensorflow.keras.models import Sequential\n",
    "#Sequential is a type of Keras model that allows you to build neural networks layer by layer in a sequential manner.\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\n",
    "'''Conv2D: Performs 2D spatial convolution to extract features from input images.\n",
    "MaxPooling2D: Performs downsampling by retaining the maximum value in each region of the input feature maps.\n",
    "Flatten: Converts spatial feature maps into a 1D vector for feeding into fully connected layers.\n",
    "Dense: Represents fully connected layers for learning nonlinear relationships in the data.'''\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3936f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_dir = r\"C:\\Users\\penfr\\OneDrive\\Desktop\\Intellipaat_Python\\AI materials\\cats_dogs_dataset\" \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f768072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an ImageDataGenerator object for augmenting training images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values between [0,1]\n",
    "    rotation_range=40,  # Range for random rotations\n",
    "    width_shift_range=0.2,  # Range for random horizontal shifts\n",
    "    height_shift_range=0.2,  # Range for random vertical shifts\n",
    "    shear_range=0.2,  # Range for random shearing\n",
    "    zoom_range=0.2,  # Range for random zoom\n",
    "    horizontal_flip=True  # Randomly flip images horizontally\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b786c6a",
   "metadata": {},
   "source": [
    "Parameters like rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, and horizontal_flip are specified to apply various transformations to the images. These transformations increase the diversity of the training dataset, which helps prevent overfitting and improves the model's ability to generalize to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9350c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create a generator for training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, \"PetImages\"),  # Directory containing training images\n",
    "    target_size=(150, 150),  # Resize images to 150x150 pixels\n",
    "    batch_size=32,  # Number of images in each batch\n",
    "    class_mode='binary'  # Binary class mode for binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f94c6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Splitting the dataset into train and test sets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_files, test_files \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241m.\u001b[39mfilepaths, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into train and test sets\n",
    "train_files, test_files = train_test_split(train_generator.filepaths, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c80e3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building:\n",
    "# Construct a Convolutional Neural Network using TensorFlow and Keras\n",
    "model = Sequential([\n",
    "    # Add a 2D convolutional layer with 32 filters, each with a 3x3 kernel size,\n",
    "    # ReLU activation, and input shape of (150, 150, 3) for RGB images\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    # Convolutional layers are responsible for extracting features from input images.\n",
    "    # The first convolutional layer typically learns low-level features like edges and textures.\n",
    "\n",
    "    # Add a max pooling layer with a pool size of 2x2\n",
    "    MaxPooling2D(2, 2),\n",
    "    # Max pooling layers reduce the spatial dimensions of the feature maps, reducing computation\n",
    "    # and providing translation invariance to some extent.\n",
    "\n",
    "    # Add another 2D convolutional layer with 64 filters and a 3x3 kernel size, followed by ReLU activation\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    # Additional convolutional layers learn higher-level features by combining lower-level features.\n",
    "    # ReLU activation introduces non-linearity to the network.\n",
    "\n",
    "    # Add another max pooling layer\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    # Add a third 2D convolutional layer with 128 filters and a 3x3 kernel size, followed by ReLU activation\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "\n",
    "    # Add another max pooling layer\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    # Add a fourth 2D convolutional layer with 128 filters and a 3x3 kernel size, followed by ReLU activation\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "\n",
    "    # Add another max pooling layer\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    # Flatten the 2D feature maps into a 1D vector\n",
    "    Flatten(),\n",
    "    # Flatten layer converts the output of convolutional layers into a format suitable for feeding\n",
    "    # into fully connected layers.\n",
    "\n",
    "    # Add a fully connected layer with 512 neurons and ReLU activation\n",
    "    Dense(512, activation='relu'),\n",
    "    # Dense layers, also known as fully connected layers, learn complex patterns in the data.\n",
    "\n",
    "    # Add the output layer with a single neuron and sigmoid activation for binary classification\n",
    "    Dense(1, activation='sigmoid')\n",
    "    # The output layer produces the final prediction, with sigmoid activation for binary classification.\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c868ffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Compile the model and train it on the prepared dataset\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Compiles the model with binary cross-entropy loss function, Adam optimizer,\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# and accuracy metric for evaluation during training.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     10\u001b[0m     train_generator,\n\u001b[0;32m     11\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39mtrain_generator\u001b[38;5;241m.\u001b[39msamples\u001b[38;5;241m/\u001b[39mtrain_generator\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m     12\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m\n\u001b[0;32m     13\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Training:\n",
    "# Compile the model and train it on the prepared dataset\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# Compiles the model with binary cross-entropy loss function, Adam optimizer,\n",
    "# and accuracy metric for evaluation during training.\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=20\n",
    ")\n",
    "# Fits the model to the training data generator for a specified number of epochs,\n",
    "# with steps_per_epoch calculated based on the number of samples and batch size in the generator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation:\n",
    "# Evaluate the model's performance on the validation set during training\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# Initialize an ImageDataGenerator for preprocessing the test images.\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, \"PetImages\"),\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "# Create a generator for test data from the test directory, with resizing to (150, 150) pixels,\n",
    "# batch size of 32, and binary class mode for binary classification.\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "# Evaluates the model's performance on the test data generator, calculating test loss and accuracy.\n",
    "\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "# Prints the test accuracy obtained from evaluating the model on the test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction:\n",
    "# Implement a system to make predictions on new images\n",
    "sample_img_path = \"path_to_sample_image.jpg\"\n",
    "# Specify the path to the sample image for prediction.\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(sample_img_path, target_size=(150, 150))\n",
    "# Load the sample image and resize it to (150, 150) pixels.\n",
    "\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "# Convert the image to a numpy array.\n",
    "\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "# Expand the dimensions of the image array to match the model's input shape.\n",
    "\n",
    "img_array /= 255.\n",
    "# Normalize pixel values to the range [0, 1].\n",
    "\n",
    "prediction = model.predict(img_array)\n",
    "# Make predictions on the image array using the trained model.\n",
    "\n",
    "if prediction[0] > 0.5:\n",
    "    print(\"Dog\")\n",
    "else:\n",
    "    print(\"Cat\")\n",
    "# Print the predicted class based on the model's prediction probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385f186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
